{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "501268a1-2347-46dd-ae4e-d4424b0261a9",
   "metadata": {},
   "source": [
    "# Best Model Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d682a9ac-99fa-4394-aaff-3844701b070f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5b91abe-37c4-4478-9207-7b7d4b5daf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from features.features_dataset import FeaturesDataset\n",
    "from models.fully_connected_classifier import FullyConnectedClassifier\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e753e-a150-4713-89fe-ee55f0a47f4e",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65df135b-2862-4ce3-9a96-51bf4048106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path= r\"..\\data\\processed\\features_dataset.csv\"\n",
    "feat_dataset = FeaturesDataset.load_from_csv(csv_path, label_columns= ['id_measurement', 'id_performance', 'datetime', 'plant', 'generation', 'num_eurythmy', 'initial_second', 'eurythmy_letter'],\n",
    "                                        variable_columns= ['mfcc_1_avg', 'mfcc_2_avg', 'mfcc_3_avg', 'mfcc_4_avg', 'mfcc_5_avg', 'mfcc_6_avg', 'mfcc_7_avg', 'mfcc_8_avg', 'mfcc_9_avg', 'mfcc_10_avg', 'mfcc_11_avg', 'mfcc_12_avg', 'mfcc_13_avg', 'mfcc_1_std', 'mfcc_2_std', 'mfcc_3_std', 'mfcc_4_std', 'mfcc_5_std', 'mfcc_6_std', 'mfcc_7_std', 'mfcc_8_std', 'mfcc_9_std', 'mfcc_10_std', 'mfcc_11_std', 'mfcc_12_std', 'mfcc_13_std', 'zero_crossing_rate', 'root_mean_square_energy', 'slope_sign_changes_ratio', 'hjorth_mobility', 'hjorth_complexity', 'mean', 'variance', 'standard_deviation', 'interquartile_range', 'skewness', 'kurtosis', 'dfa'],\n",
    "                                        target_column=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "becfc4f0-3364-4948-a197-9da98cfbc374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148682, 52)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_dataset.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201f79aa-6c54-45b9-8590-1d4e4076c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dataset_path= r\"..\\data\\processed\\features_dataset\"\n",
    "feat_dataset = FeaturesDataset.load(file_path= feat_dataset_path)\n",
    "feat_dataset.features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53f9dd1-6bd5-4b1f-ae2a-ab0aeb3ceac0",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd497b5a-6843-45c2-9d22-b847f9cc7dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dataset.prepare_dataset(drop_constant= True, drop_flatness= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f3bd65-4f12-4f95-b675-74f23d101aa4",
   "metadata": {},
   "source": [
    "## RQ1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d9dc60-42bf-49e3-b9be-65982f5de922",
   "metadata": {},
   "source": [
    "Is there any difference in the signals when someone is performing eurythmy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa452b95-7c4e-4e57-bc09-477f319a28e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rq1= feat_dataset.return_subset_given_research_question(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92795233-5312-40c2-bcc4-f12027da517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_dataset, val_feat_dataset, test_feat_dataset= rq1.split_dataset(split_by_wav= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12075ed8-ce61-408c-b237-4fb3668045a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader= DataLoader(train_feat_dataset, batch_size=32, shuffle=True)\n",
    "val_loader= DataLoader(val_feat_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f13c433-15a9-447f-8e0b-c7d552594919",
   "metadata": {},
   "outputs": [],
   "source": [
    "klk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7262c4-f677-4d44-8d17-ce350dd882ff",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4435d97a-0b9c-4e45-9f59-fe282c518fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the Dataset for the datapoints concerning RQ1\n",
    "\n",
    "rq1_train_feat_dataset= train_feat_dataset.copy()\n",
    "processed_train_indexes, train_targets= ped.get_indexes_and_targets_by_rq(1, rq1_train_feat_dataset.features)\n",
    "rq1_train_feat_dataset.features= rq1_train_feat_dataset.features.iloc[processed_train_indexes]\n",
    "rq1_train_feat_dataset.features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "rq1_test_feat_dataset= test_feat_dataset.copy()\n",
    "processed_test_indexes, test_targets= ped.get_indexes_and_targets_by_rq(1, rq1_test_feat_dataset.features)\n",
    "rq1_test_feat_dataset.features= rq1_test_feat_dataset.features.iloc[processed_test_indexes]\n",
    "rq1_test_feat_dataset.features.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d747c2b-158c-46d3-a7ab-1554a5c30d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the features that are correlated in the training data\n",
    "train_cols= rq1_train_feat_dataset.reduce_features(targets= train_targets, corr_threshold=0.75)\n",
    "rq1_test_feat_dataset.keep_only_specified_variable_columns(train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a14a0b1-99db-4533-a149-cede11efaa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features ?????\n",
    "normalization_params= rq1_train_feat_dataset.normalize_features()\n",
    "rq1_test_feat_dataset.apply_normalization(normalization_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c970865-b9c7-4ef9-9944-e6014c62817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rq1_train_feat_dataset.objective_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55003dfa-44b3-4c3c-9264-e0fe524dd042",
   "metadata": {},
   "outputs": [],
   "source": [
    "rq1_test_feat_dataset.objective_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1387c208-a208-4544-8da6-0a9303847507",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader= rq1_train_feat_dataset.get_variable_features_loader(train_targets)\n",
    "test_loader= rq1_test_feat_dataset.get_variable_features_loader(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa93376-93bd-46c4-97ca-7b0e1ba514cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_counts_and_percentages(values):\n",
    "    count = Counter(values)\n",
    "    total = sum(count.values())\n",
    "    \n",
    "    print(\"Counts and Percentages:\")\n",
    "    for key, value in count.items():\n",
    "        percentage = (value / total) * 100\n",
    "        print(f\"Class {key}: Count = {value}, Percentage = {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47035379-d2dd-41d0-a018-23f14fd98eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "print_counts_and_percentages(train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7633f003-dd8c-4308-af5f-403f99aa6548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "print_counts_and_percentages(test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f86f6f5-14f2-44ed-9dda-c6fd5ba81886",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a5c218-a6b0-43ba-9b66-0002bc2bf05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769746a2-965f-4928-9b6a-a5a1e4f5d711",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size= len(rq1_train_feat_dataset.variable_columns)\n",
    "output_size= 2\n",
    "num_epochs = 50\n",
    "\n",
    "parameters = {\n",
    "    'learning_rate': 0.001,\n",
    "    'dense_units': 128,\n",
    "    'dense_layers': 1,\n",
    "    'dropout_rate': 0.2,\n",
    "    'early_stopping_patience': 7\n",
    "}\n",
    "\n",
    "model = FullyConnectedClassifier(input_size= input_size, output_size= output_size, parameters= parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922201a6-7c48-4915-9733-434a8ce3831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_model(train_loader, test_loader, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55a29ad-f615-4ea0-8b6f-f92ce79d125b",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780fd1cc-6d6c-47e3-aa01-9be0615186f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8da217-de67-4d9f-ae1d-036f51e4f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_labels = []\n",
    "for _, labels in test_loader:\n",
    "    actual_labels.extend(labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2609c48b-aecf-463b-a3c4-70a543a054e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = sum(p == t for p, t in zip(test_predictions, actual_labels))\n",
    "accuracy = correct_predictions / len(actual_labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec56b49-e194-4244-88eb-a4fb3483cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Assuming your task is a classification task\n",
    "precision = precision_score(actual_labels, test_predictions, average='macro')\n",
    "recall = recall_score(actual_labels, test_predictions, average='macro')\n",
    "f1 = f1_score(actual_labels, test_predictions, average='macro')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(actual_labels, test_predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423922b4-2b77-493e-bee9-333fc2ec32b9",
   "metadata": {},
   "source": [
    "## RQ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0986c19-6265-48e0-a18a-43cd53a50fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data preparation\n",
    "\n",
    "# Reduce the Dataset for the datapoints concerning rq2\n",
    "\n",
    "rq2_train_feat_dataset= train_feat_dataset.copy()\n",
    "processed_train_indexes, train_targets= ped.get_indexes_and_targets_by_rq(2, rq2_train_feat_dataset.features)\n",
    "rq2_train_feat_dataset.features= rq2_train_feat_dataset.features.iloc[processed_train_indexes]\n",
    "rq2_train_feat_dataset.features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "rq2_test_feat_dataset= test_feat_dataset.copy()\n",
    "processed_test_indexes, test_targets= ped.get_indexes_and_targets_by_rq(2, rq2_test_feat_dataset.features)\n",
    "rq2_test_feat_dataset.features= rq2_test_feat_dataset.features.iloc[processed_test_indexes]\n",
    "rq2_test_feat_dataset.features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Reduce the features that are correlated in the training data\n",
    "train_cols= rq2_train_feat_dataset.reduce_features(targets= train_targets, corr_threshold=0.75)\n",
    "rq2_test_feat_dataset.keep_only_specified_variable_columns(train_cols)\n",
    "\n",
    "# Normalize features\n",
    "normalization_params= rq2_train_feat_dataset.normalize_features()\n",
    "rq2_test_feat_dataset.apply_normalization(normalization_params)\n",
    "\n",
    "rq2_train_feat_dataset.objective_features.head()\n",
    "\n",
    "rq2_test_feat_dataset.objective_features.head()\n",
    "\n",
    "train_loader= rq2_train_feat_dataset.get_variable_features_loader(train_targets)\n",
    "test_loader= rq2_test_feat_dataset.get_variable_features_loader(test_targets)\n",
    "\n",
    "# Train dataset\n",
    "print_counts_and_percentages(train_targets)\n",
    "\n",
    "# Test dataset\n",
    "print_counts_and_percentages(test_targets)\n",
    "\n",
    "### Training\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "input_size= len(rq2_train_feat_dataset.variable_columns)\n",
    "output_size= 3\n",
    "num_epochs = 50\n",
    "\n",
    "parameters = {\n",
    "    'learning_rate': 0.0003,\n",
    "    'dense_units': 128,\n",
    "    'dense_layers': 2,\n",
    "    'dropout_rate': 0.2\n",
    "}\n",
    "\n",
    "model = FullyConnectedClassifier(input_size= input_size, output_size= output_size, parameters= parameters)\n",
    "\n",
    "model.train_model(train_loader, test_loader, num_epochs)\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "test_predictions = model.predict(test_loader)\n",
    "\n",
    "actual_labels = []\n",
    "for _, labels in test_loader:\n",
    "    actual_labels.extend(labels.tolist())\n",
    "\n",
    "correct_predictions = sum(p == t for p, t in zip(test_predictions, actual_labels))\n",
    "accuracy = correct_predictions / len(actual_labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Assuming your task is a classification task\n",
    "precision = precision_score(actual_labels, test_predictions, average='macro')\n",
    "recall = recall_score(actual_labels, test_predictions, average='macro')\n",
    "f1 = f1_score(actual_labels, test_predictions, average='macro')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(actual_labels, test_predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9446fe-ddeb-4ae5-bf39-a8c4a7d5cd12",
   "metadata": {},
   "source": [
    "## RQ3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b82a9e-242a-4094-b87d-78f17c04c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data preparation\n",
    "\n",
    "# Reduce the Dataset for the datapoints concerning rq3\n",
    "\n",
    "rq3_train_feat_dataset= train_feat_dataset.copy()\n",
    "processed_train_indexes, train_targets= ped.get_indexes_and_targets_by_rq(3, rq3_train_feat_dataset.features)\n",
    "rq3_train_feat_dataset.features= rq3_train_feat_dataset.features.iloc[processed_train_indexes]\n",
    "rq3_train_feat_dataset.features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "rq3_test_feat_dataset= test_feat_dataset.copy()\n",
    "processed_test_indexes, test_targets= ped.get_indexes_and_targets_by_rq(3, rq3_test_feat_dataset.features)\n",
    "rq3_test_feat_dataset.features= rq3_test_feat_dataset.features.iloc[processed_test_indexes]\n",
    "rq3_test_feat_dataset.features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Reduce the features that are correlated in the training data\n",
    "train_cols= rq3_train_feat_dataset.reduce_features(targets= train_targets, corr_threshold=0.75)\n",
    "rq3_test_feat_dataset.keep_only_specified_variable_columns(train_cols)\n",
    "\n",
    "# Normalize features\n",
    "normalization_params= rq3_train_feat_dataset.normalize_features()\n",
    "rq3_test_feat_dataset.apply_normalization(normalization_params)\n",
    "\n",
    "rq3_train_feat_dataset.objective_features.head()\n",
    "\n",
    "rq3_test_feat_dataset.objective_features.head()\n",
    "\n",
    "train_loader= rq3_train_feat_dataset.get_variable_features_loader(train_targets)\n",
    "test_loader= rq3_test_feat_dataset.get_variable_features_loader(test_targets)\n",
    "\n",
    "# Train dataset\n",
    "print_counts_and_percentages(train_targets)\n",
    "\n",
    "# Test dataset\n",
    "print_counts_and_percentages(test_targets)\n",
    "\n",
    "### Training\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "input_size= len(rq3_train_feat_dataset.variable_columns)\n",
    "output_size= 4\n",
    "num_epochs = 50\n",
    "\n",
    "parameters = {\n",
    "    'learning_rate': 0.0003,\n",
    "    'dense_units': 64,\n",
    "    'dense_layers': 1,\n",
    "    'dropout_rate': 0\n",
    "}\n",
    "\n",
    "model = FullyConnectedClassifier(input_size= input_size, output_size= output_size, parameters= parameters)\n",
    "\n",
    "model.train_model(train_loader, test_loader, num_epochs)\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "test_predictions = model.predict(test_loader)\n",
    "\n",
    "actual_labels = []\n",
    "for _, labels in test_loader:\n",
    "    actual_labels.extend(labels.tolist())\n",
    "\n",
    "correct_predictions = sum(p == t for p, t in zip(test_predictions, actual_labels))\n",
    "accuracy = correct_predictions / len(actual_labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Assuming your task is a classification task\n",
    "precision = precision_score(actual_labels, test_predictions, average='macro')\n",
    "recall = recall_score(actual_labels, test_predictions, average='macro')\n",
    "f1 = f1_score(actual_labels, test_predictions, average='macro')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(actual_labels, test_predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2518c098-1edb-4e4e-8998-18553d44bd8a",
   "metadata": {},
   "source": [
    "## RQ4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d02cffc-7d99-4976-8fa0-d9add1866aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data preparation\n",
    "\n",
    "# Reduce the Dataset for the datapoints concerning rq4\n",
    "\n",
    "rq4_train_feat_dataset= train_feat_dataset.copy()\n",
    "processed_train_indexes, train_targets= ped.get_indexes_and_targets_by_rq(4, rq4_train_feat_dataset.features)\n",
    "rq4_train_feat_dataset.features= rq4_train_feat_dataset.features.iloc[processed_train_indexes]\n",
    "rq4_train_feat_dataset.features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "rq4_test_feat_dataset= test_feat_dataset.copy()\n",
    "processed_test_indexes, test_targets= ped.get_indexes_and_targets_by_rq(4, rq4_test_feat_dataset.features)\n",
    "rq4_test_feat_dataset.features= rq4_test_feat_dataset.features.iloc[processed_test_indexes]\n",
    "rq4_test_feat_dataset.features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Reduce the features that are correlated in the training data\n",
    "train_cols= rq4_train_feat_dataset.reduce_features(targets= train_targets, corr_threshold=0.75)\n",
    "rq4_test_feat_dataset.keep_only_specified_variable_columns(train_cols)\n",
    "\n",
    "# Normalize features\n",
    "normalization_params= rq4_train_feat_dataset.normalize_features()\n",
    "rq4_test_feat_dataset.apply_normalization(normalization_params)\n",
    "\n",
    "rq4_train_feat_dataset.objective_features.head()\n",
    "\n",
    "rq4_test_feat_dataset.objective_features.head()\n",
    "\n",
    "train_loader= rq4_train_feat_dataset.get_variable_features_loader(train_targets)\n",
    "test_loader= rq4_test_feat_dataset.get_variable_features_loader(test_targets)\n",
    "\n",
    "# Train dataset\n",
    "print_counts_and_percentages(train_targets)\n",
    "\n",
    "# Test dataset\n",
    "print_counts_and_percentages(test_targets)\n",
    "\n",
    "### Training\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "input_size= len(rq4_train_feat_dataset.variable_columns)\n",
    "output_size= 4\n",
    "num_epochs = 50\n",
    "\n",
    "parameters = {\n",
    "    'learning_rate': 0.0003,\n",
    "    'dense_units': 64,\n",
    "    'dense_layers': 2,\n",
    "    'dropout_rate': 0.2\n",
    "}\n",
    "\n",
    "model = FullyConnectedClassifier(input_size= input_size, output_size= output_size, parameters= parameters)\n",
    "\n",
    "model.train_model(train_loader, test_loader, num_epochs)\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "test_predictions = model.predict(test_loader)\n",
    "\n",
    "actual_labels = []\n",
    "for _, labels in test_loader:\n",
    "    actual_labels.extend(labels.tolist())\n",
    "\n",
    "correct_predictions = sum(p == t for p, t in zip(test_predictions, actual_labels))\n",
    "accuracy = correct_predictions / len(actual_labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Assuming your task is a classification task\n",
    "precision = precision_score(actual_labels, test_predictions, average='macro')\n",
    "recall = recall_score(actual_labels, test_predictions, average='macro')\n",
    "f1 = f1_score(actual_labels, test_predictions, average='macro')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(actual_labels, test_predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
