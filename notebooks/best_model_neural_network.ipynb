{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "501268a1-2347-46dd-ae4e-d4424b0261a9",
   "metadata": {},
   "source": [
    "# Best Model Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d682a9ac-99fa-4394-aaff-3844701b070f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5b91abe-37c4-4478-9207-7b7d4b5daf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data.preparation_eurythmy_data as ped\n",
    "from features.features_dataset import FeaturesDataset\n",
    "from models.fully_connected_classifier import FullyConnectedClassifier\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e753e-a150-4713-89fe-ee55f0a47f4e",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d407d710-98f1-4a82-bba8-a976cbdfaf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dataset_path= r\"..\\data\\processed\\features_dataset\"\n",
    "feat_dataset = FeaturesDataset.load(file_path= feat_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11c94f00-f95a-4db8-8708-1696682e98f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148682, 52)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_dataset.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4970d666-b65d-4e1d-abda-a125ce0e128f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_measurement</th>\n",
       "      <th>id_performance</th>\n",
       "      <th>datetime</th>\n",
       "      <th>plant</th>\n",
       "      <th>generation</th>\n",
       "      <th>num_eurythmy</th>\n",
       "      <th>initial_second</th>\n",
       "      <th>eurythmy_letter</th>\n",
       "      <th>mfcc_1_avg</th>\n",
       "      <th>mfcc_2_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>flatness_ratio_100</th>\n",
       "      <th>hjorth_mobility</th>\n",
       "      <th>hjorth_complexity</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "      <th>standard_deviation</th>\n",
       "      <th>interquartile_range</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>dfa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-04-29</td>\n",
       "      <td>salad</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>-232.006348</td>\n",
       "      <td>87.030777</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>8171.888932</td>\n",
       "      <td>1.013423</td>\n",
       "      <td>0.013814</td>\n",
       "      <td>0.117533</td>\n",
       "      <td>0.181950</td>\n",
       "      <td>0.224347</td>\n",
       "      <td>-0.509566</td>\n",
       "      <td>1.586800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-04-29</td>\n",
       "      <td>salad</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>-250.255188</td>\n",
       "      <td>85.806961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>8190.134755</td>\n",
       "      <td>0.865816</td>\n",
       "      <td>0.015855</td>\n",
       "      <td>0.125916</td>\n",
       "      <td>0.181950</td>\n",
       "      <td>0.418608</td>\n",
       "      <td>-0.598494</td>\n",
       "      <td>1.466508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-04-29</td>\n",
       "      <td>salad</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>-278.646332</td>\n",
       "      <td>68.209419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9941</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>13453.068166</td>\n",
       "      <td>1.289050</td>\n",
       "      <td>0.054860</td>\n",
       "      <td>0.234221</td>\n",
       "      <td>0.454875</td>\n",
       "      <td>-0.314866</td>\n",
       "      <td>-1.620937</td>\n",
       "      <td>1.336079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-04-29</td>\n",
       "      <td>salad</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>-276.146942</td>\n",
       "      <td>74.985809</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>9082.708501</td>\n",
       "      <td>1.374193</td>\n",
       "      <td>0.010778</td>\n",
       "      <td>0.103816</td>\n",
       "      <td>0.090975</td>\n",
       "      <td>-0.524587</td>\n",
       "      <td>0.561958</td>\n",
       "      <td>1.404778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-04-29</td>\n",
       "      <td>salad</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>-299.724091</td>\n",
       "      <td>62.226551</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>12209.774692</td>\n",
       "      <td>1.289022</td>\n",
       "      <td>0.029832</td>\n",
       "      <td>0.172718</td>\n",
       "      <td>0.272925</td>\n",
       "      <td>-0.852706</td>\n",
       "      <td>-0.735823</td>\n",
       "      <td>1.509514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_measurement  id_performance    datetime  plant  generation  \\\n",
       "0               1               1  2023-04-29  salad           1   \n",
       "1               1               1  2023-04-29  salad           1   \n",
       "2               1               1  2023-04-29  salad           1   \n",
       "3               1               1  2023-04-29  salad           1   \n",
       "4               1               1  2023-04-29  salad           1   \n",
       "\n",
       "   num_eurythmy  initial_second eurythmy_letter  mfcc_1_avg  mfcc_2_avg  ...  \\\n",
       "0             1             0.0            None -232.006348   87.030777  ...   \n",
       "1             1             1.0            None -250.255188   85.806961  ...   \n",
       "2             1             2.0            None -278.646332   68.209419  ...   \n",
       "3             1             3.0            None -276.146942   74.985809  ...   \n",
       "4             1             4.0            None -299.724091   62.226551  ...   \n",
       "\n",
       "   flatness_ratio_100  hjorth_mobility  hjorth_complexity      mean  variance  \\\n",
       "0              1.0000         0.000128        8171.888932  1.013423  0.013814   \n",
       "1              0.9894         0.000129        8190.134755  0.865816  0.015855   \n",
       "2              0.9941         0.000077       13453.068166  1.289050  0.054860   \n",
       "3              1.0000         0.000112        9082.708501  1.374193  0.010778   \n",
       "4              1.0000         0.000085       12209.774692  1.289022  0.029832   \n",
       "\n",
       "   standard_deviation  interquartile_range  skewness  kurtosis       dfa  \n",
       "0            0.117533             0.181950  0.224347 -0.509566  1.586800  \n",
       "1            0.125916             0.181950  0.418608 -0.598494  1.466508  \n",
       "2            0.234221             0.454875 -0.314866 -1.620937  1.336079  \n",
       "3            0.103816             0.090975 -0.524587  0.561958  1.404778  \n",
       "4            0.172718             0.272925 -0.852706 -0.735823  1.509514  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_dataset.features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53f9dd1-6bd5-4b1f-ae2a-ab0aeb3ceac0",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1477be61-487c-4ba5-9311-39d00c0023ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop constant signals\n",
    "indexes_constant_value = feat_dataset.features[feat_dataset.features['flatness_ratio_100'] == 1].index.tolist()\n",
    "feat_dataset.drop_rows(indexes_constant_value)\n",
    "\n",
    "# Drop columns\n",
    "columns=['duration_seconds', 'flatness_ratio_10000','flatness_ratio_5000', 'flatness_ratio_1000', 'flatness_ratio_500','flatness_ratio_100']\n",
    "feat_dataset.drop_columns(columns_to_drop=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f888fed5-eb33-4f94-b5dd-b202ceb18476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120478, 46)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_dataset.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60a5e384-48e6-4564-97b7-fbd2547d2eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Train, Validation and Test Indexes\n",
    "train_indexes, val_indexes, test_indexes= ped.get_train_val_test_indexes(df= feat_dataset.features)\n",
    "train_val_indexes= train_indexes + val_indexes\n",
    "\n",
    "# Split the training data\n",
    "train_feat_dataset= feat_dataset.copy()\n",
    "train_feat_dataset.features= feat_dataset.features.iloc[train_val_indexes]\n",
    "train_feat_dataset.features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Split the validation data\n",
    "test_feat_dataset= feat_dataset.copy()\n",
    "test_feat_dataset.features= feat_dataset.features.iloc[test_indexes]\n",
    "test_feat_dataset.features.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb1c4277-c41b-4323-9e46-b38571969375",
   "metadata": {},
   "outputs": [],
   "source": [
    "del feat_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f3bd65-4f12-4f95-b675-74f23d101aa4",
   "metadata": {},
   "source": [
    "## RQ1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d9dc60-42bf-49e3-b9be-65982f5de922",
   "metadata": {},
   "source": [
    "Is there any difference in the signals when someone is performing eurythmy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7262c4-f677-4d44-8d17-ce350dd882ff",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4435d97a-0b9c-4e45-9f59-fe282c518fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the Dataset for the datapoints concerning RQ1\n",
    "\n",
    "rq1_train_feat_dataset= train_feat_dataset.copy()\n",
    "processed_train_indexes, train_targets= ped.get_indexes_and_targets_by_rq(1, rq1_train_feat_dataset.features)\n",
    "rq1_train_feat_dataset.features= rq1_train_feat_dataset.features.iloc[processed_train_indexes]\n",
    "rq1_train_feat_dataset.features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "rq1_test_feat_dataset= test_feat_dataset.copy()\n",
    "processed_test_indexes, test_targets= ped.get_indexes_and_targets_by_rq(1, rq1_test_feat_dataset.features)\n",
    "rq1_test_feat_dataset.features= rq1_test_feat_dataset.features.iloc[processed_test_indexes]\n",
    "rq1_test_feat_dataset.features.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d747c2b-158c-46d3-a7ab-1554a5c30d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced variable features from 38 to 12.\n"
     ]
    }
   ],
   "source": [
    "# Reduce the features that are correlated in the training data\n",
    "train_cols= rq1_train_feat_dataset.reduce_features(targets= train_targets, corr_threshold=0.75)\n",
    "rq1_test_feat_dataset.keep_only_specified_variable_columns(train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a14a0b1-99db-4533-a149-cede11efaa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable features were properly normalized using 'zscore' method.\n",
      "Applied z-score normalization.\n"
     ]
    }
   ],
   "source": [
    "# Normalize features\n",
    "normalization_params= rq1_train_feat_dataset.normalize_features()\n",
    "rq1_test_feat_dataset.apply_normalization(normalization_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c970865-b9c7-4ef9-9944-e6014c62817b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_1_avg</th>\n",
       "      <th>mfcc_1_std</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>root_mean_square_energy</th>\n",
       "      <th>slope_sign_changes_ratio</th>\n",
       "      <th>hjorth_mobility</th>\n",
       "      <th>hjorth_complexity</th>\n",
       "      <th>mean</th>\n",
       "      <th>standard_deviation</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>dfa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.188361</td>\n",
       "      <td>1.299811</td>\n",
       "      <td>-0.64364</td>\n",
       "      <td>1.578563</td>\n",
       "      <td>-0.426619</td>\n",
       "      <td>-0.312965</td>\n",
       "      <td>-0.261353</td>\n",
       "      <td>2.028067</td>\n",
       "      <td>-0.567070</td>\n",
       "      <td>0.230537</td>\n",
       "      <td>-0.053963</td>\n",
       "      <td>-1.572177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.316321</td>\n",
       "      <td>1.064484</td>\n",
       "      <td>-0.64364</td>\n",
       "      <td>1.215891</td>\n",
       "      <td>-0.367199</td>\n",
       "      <td>-0.324300</td>\n",
       "      <td>-0.250261</td>\n",
       "      <td>1.749495</td>\n",
       "      <td>-0.560078</td>\n",
       "      <td>-0.576037</td>\n",
       "      <td>-0.033285</td>\n",
       "      <td>-0.711235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.431995</td>\n",
       "      <td>0.992463</td>\n",
       "      <td>-0.64364</td>\n",
       "      <td>1.434828</td>\n",
       "      <td>-0.353487</td>\n",
       "      <td>-0.489026</td>\n",
       "      <td>-0.133136</td>\n",
       "      <td>1.917698</td>\n",
       "      <td>-0.565244</td>\n",
       "      <td>0.209828</td>\n",
       "      <td>-0.020470</td>\n",
       "      <td>-0.387445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.272330</td>\n",
       "      <td>1.256343</td>\n",
       "      <td>-0.64364</td>\n",
       "      <td>1.604177</td>\n",
       "      <td>-0.376341</td>\n",
       "      <td>-0.409596</td>\n",
       "      <td>-0.195232</td>\n",
       "      <td>2.047841</td>\n",
       "      <td>-0.573485</td>\n",
       "      <td>-1.291495</td>\n",
       "      <td>0.039514</td>\n",
       "      <td>-0.506190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520903</td>\n",
       "      <td>0.953421</td>\n",
       "      <td>-0.64364</td>\n",
       "      <td>1.219014</td>\n",
       "      <td>-0.307779</td>\n",
       "      <td>-0.321820</td>\n",
       "      <td>-0.249028</td>\n",
       "      <td>1.741855</td>\n",
       "      <td>-0.268600</td>\n",
       "      <td>-0.206831</td>\n",
       "      <td>-0.059281</td>\n",
       "      <td>-0.387946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mfcc_1_avg  mfcc_1_std  zero_crossing_rate  root_mean_square_energy  \\\n",
       "0    0.188361    1.299811            -0.64364                 1.578563   \n",
       "1    0.316321    1.064484            -0.64364                 1.215891   \n",
       "2    0.431995    0.992463            -0.64364                 1.434828   \n",
       "3    0.272330    1.256343            -0.64364                 1.604177   \n",
       "4    0.520903    0.953421            -0.64364                 1.219014   \n",
       "\n",
       "   slope_sign_changes_ratio  hjorth_mobility  hjorth_complexity      mean  \\\n",
       "0                 -0.426619        -0.312965          -0.261353  2.028067   \n",
       "1                 -0.367199        -0.324300          -0.250261  1.749495   \n",
       "2                 -0.353487        -0.489026          -0.133136  1.917698   \n",
       "3                 -0.376341        -0.409596          -0.195232  2.047841   \n",
       "4                 -0.307779        -0.321820          -0.249028  1.741855   \n",
       "\n",
       "   standard_deviation  skewness  kurtosis       dfa  \n",
       "0           -0.567070  0.230537 -0.053963 -1.572177  \n",
       "1           -0.560078 -0.576037 -0.033285 -0.711235  \n",
       "2           -0.565244  0.209828 -0.020470 -0.387445  \n",
       "3           -0.573485 -1.291495  0.039514 -0.506190  \n",
       "4           -0.268600 -0.206831 -0.059281 -0.387946  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rq1_train_feat_dataset.objective_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55003dfa-44b3-4c3c-9264-e0fe524dd042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_1_avg</th>\n",
       "      <th>mfcc_1_std</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>root_mean_square_energy</th>\n",
       "      <th>slope_sign_changes_ratio</th>\n",
       "      <th>hjorth_mobility</th>\n",
       "      <th>hjorth_complexity</th>\n",
       "      <th>mean</th>\n",
       "      <th>standard_deviation</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>dfa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.534499</td>\n",
       "      <td>0.584997</td>\n",
       "      <td>0.815566</td>\n",
       "      <td>-0.307090</td>\n",
       "      <td>-0.412907</td>\n",
       "      <td>-0.178979</td>\n",
       "      <td>-0.144306</td>\n",
       "      <td>0.071243</td>\n",
       "      <td>0.665108</td>\n",
       "      <td>0.557660</td>\n",
       "      <td>-0.067981</td>\n",
       "      <td>-0.353997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.424618</td>\n",
       "      <td>-1.543969</td>\n",
       "      <td>0.815566</td>\n",
       "      <td>-0.781438</td>\n",
       "      <td>-0.412907</td>\n",
       "      <td>1.364723</td>\n",
       "      <td>-0.575708</td>\n",
       "      <td>-0.116880</td>\n",
       "      <td>-0.346188</td>\n",
       "      <td>0.969524</td>\n",
       "      <td>-0.020295</td>\n",
       "      <td>-1.117752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.797651</td>\n",
       "      <td>-1.197263</td>\n",
       "      <td>-0.643640</td>\n",
       "      <td>-0.204711</td>\n",
       "      <td>-0.380911</td>\n",
       "      <td>-0.676213</td>\n",
       "      <td>0.545226</td>\n",
       "      <td>0.644185</td>\n",
       "      <td>-0.407335</td>\n",
       "      <td>-1.076927</td>\n",
       "      <td>0.066848</td>\n",
       "      <td>-1.016913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.001029</td>\n",
       "      <td>-1.041649</td>\n",
       "      <td>-0.643640</td>\n",
       "      <td>-0.416091</td>\n",
       "      <td>-0.358058</td>\n",
       "      <td>0.596411</td>\n",
       "      <td>-0.486407</td>\n",
       "      <td>0.458802</td>\n",
       "      <td>-0.294886</td>\n",
       "      <td>-0.331715</td>\n",
       "      <td>-0.032258</td>\n",
       "      <td>-0.543545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.523638</td>\n",
       "      <td>0.880075</td>\n",
       "      <td>-0.643640</td>\n",
       "      <td>-0.062416</td>\n",
       "      <td>-0.399194</td>\n",
       "      <td>-0.516748</td>\n",
       "      <td>0.126405</td>\n",
       "      <td>0.696169</td>\n",
       "      <td>0.043693</td>\n",
       "      <td>-0.409966</td>\n",
       "      <td>-0.051108</td>\n",
       "      <td>-0.365152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mfcc_1_avg  mfcc_1_std  zero_crossing_rate  root_mean_square_energy  \\\n",
       "0    0.534499    0.584997            0.815566                -0.307090   \n",
       "1    0.424618   -1.543969            0.815566                -0.781438   \n",
       "2    0.797651   -1.197263           -0.643640                -0.204711   \n",
       "3    1.001029   -1.041649           -0.643640                -0.416091   \n",
       "4    0.523638    0.880075           -0.643640                -0.062416   \n",
       "\n",
       "   slope_sign_changes_ratio  hjorth_mobility  hjorth_complexity      mean  \\\n",
       "0                 -0.412907        -0.178979          -0.144306  0.071243   \n",
       "1                 -0.412907         1.364723          -0.575708 -0.116880   \n",
       "2                 -0.380911        -0.676213           0.545226  0.644185   \n",
       "3                 -0.358058         0.596411          -0.486407  0.458802   \n",
       "4                 -0.399194        -0.516748           0.126405  0.696169   \n",
       "\n",
       "   standard_deviation  skewness  kurtosis       dfa  \n",
       "0            0.665108  0.557660 -0.067981 -0.353997  \n",
       "1           -0.346188  0.969524 -0.020295 -1.117752  \n",
       "2           -0.407335 -1.076927  0.066848 -1.016913  \n",
       "3           -0.294886 -0.331715 -0.032258 -0.543545  \n",
       "4            0.043693 -0.409966 -0.051108 -0.365152  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rq1_test_feat_dataset.objective_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1387c208-a208-4544-8da6-0a9303847507",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader= rq1_train_feat_dataset.get_variable_features_loader(train_targets)\n",
    "test_loader= rq1_test_feat_dataset.get_variable_features_loader(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfa93376-93bd-46c4-97ca-7b0e1ba514cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_counts_and_percentages(values):\n",
    "    count = Counter(values)\n",
    "    total = sum(count.values())\n",
    "    \n",
    "    print(\"Counts and Percentages:\")\n",
    "    for key, value in count.items():\n",
    "        percentage = (value / total) * 100\n",
    "        print(f\"Class {key}: Count = {value}, Percentage = {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47035379-d2dd-41d0-a018-23f14fd98eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts and Percentages:\n",
      "Class 1: Count = 30155, Percentage = 46.44%\n",
      "Class 0: Count = 34785, Percentage = 53.56%\n"
     ]
    }
   ],
   "source": [
    "# Train dataset\n",
    "print_counts_and_percentages(train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7633f003-dd8c-4308-af5f-403f99aa6548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts and Percentages:\n",
      "Class 1: Count = 7608, Percentage = 46.63%\n",
      "Class 0: Count = 8706, Percentage = 53.37%\n"
     ]
    }
   ],
   "source": [
    "# Test dataset\n",
    "print_counts_and_percentages(test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f86f6f5-14f2-44ed-9dda-c6fd5ba81886",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47a5c218-a6b0-43ba-9b66-0002bc2bf05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "769746a2-965f-4928-9b6a-a5a1e4f5d711",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size= len(rq1_train_feat_dataset.variable_columns)\n",
    "output_size= 2\n",
    "num_epochs = 50\n",
    "\n",
    "parameters = {\n",
    "    'learning_rate': 0.001,\n",
    "    'dense_units': 128,\n",
    "    'dense_layers': 1,\n",
    "    'dropout_rate': 0.2\n",
    "}\n",
    "\n",
    "model = FullyConnectedClassifier(input_size= input_size, output_size= output_size, parameters= parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "922201a6-7c48-4915-9733-434a8ce3831a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Training Loss: 0.6196, Training Accuracy: 0.6620, Validation Loss: 0.5993\n",
      "Epoch 2/50, Training Loss: 0.6102, Training Accuracy: 0.6695, Validation Loss: 0.5959\n",
      "Epoch 3/50, Training Loss: 0.6069, Training Accuracy: 0.6719, Validation Loss: 0.5942\n",
      "Epoch 4/50, Training Loss: 0.6046, Training Accuracy: 0.6739, Validation Loss: 0.5942\n",
      "Epoch 5/50, Training Loss: 0.6038, Training Accuracy: 0.6761, Validation Loss: 0.5904\n",
      "Epoch 6/50, Training Loss: 0.6024, Training Accuracy: 0.6766, Validation Loss: 0.5963\n",
      "Epoch 7/50, Training Loss: 0.6011, Training Accuracy: 0.6779, Validation Loss: 0.5945\n",
      "Epoch 8/50, Training Loss: 0.6003, Training Accuracy: 0.6794, Validation Loss: 0.5949\n",
      "Epoch 9/50, Training Loss: 0.5994, Training Accuracy: 0.6800, Validation Loss: 0.5844\n",
      "Epoch 10/50, Training Loss: 0.5990, Training Accuracy: 0.6803, Validation Loss: 0.5923\n",
      "Epoch 11/50, Training Loss: 0.5977, Training Accuracy: 0.6800, Validation Loss: 0.5888\n",
      "Epoch 12/50, Training Loss: 0.5978, Training Accuracy: 0.6801, Validation Loss: 0.5860\n",
      "Epoch 13/50, Training Loss: 0.5970, Training Accuracy: 0.6813, Validation Loss: 0.5941\n",
      "Epoch 14/50, Training Loss: 0.5962, Training Accuracy: 0.6808, Validation Loss: 0.5883\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "model.train_model(train_loader, test_loader, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55a29ad-f615-4ea0-8b6f-f92ce79d125b",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "780fd1cc-6d6c-47e3-aa01-9be0615186f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc8da217-de67-4d9f-ae1d-036f51e4f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_labels = []\n",
    "for _, labels in test_loader:\n",
    "    actual_labels.extend(labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2609c48b-aecf-463b-a3c4-70a543a054e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4969\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = sum(p == t for p, t in zip(test_predictions, actual_labels))\n",
    "accuracy = correct_predictions / len(actual_labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ec56b49-e194-4244-88eb-a4fb3483cdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4976\n",
      "Recall: 0.4976\n",
      "F1-Score: 0.4966\n",
      "Confusion Matrix:\n",
      " [[4248 4458]\n",
      " [3749 3859]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Assuming your task is a classification task\n",
    "precision = precision_score(actual_labels, test_predictions, average='macro')\n",
    "recall = recall_score(actual_labels, test_predictions, average='macro')\n",
    "f1 = f1_score(actual_labels, test_predictions, average='macro')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(actual_labels, test_predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423922b4-2b77-493e-bee9-333fc2ec32b9",
   "metadata": {},
   "source": [
    "## RQ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0986c19-6265-48e0-a18a-43cd53a50fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced variable features from 38 to 17.\n",
      "Variable features were properly normalized using 'zscore' method.\n",
      "Applied z-score normalization.\n",
      "Counts and Percentages:\n",
      "Class 0: Count = 9374, Percentage = 34.96%\n",
      "Class 1: Count = 8409, Percentage = 31.36%\n",
      "Class 2: Count = 9032, Percentage = 33.68%\n",
      "Counts and Percentages:\n",
      "Class 0: Count = 2366, Percentage = 34.54%\n",
      "Class 1: Count = 2170, Percentage = 31.67%\n",
      "Class 2: Count = 2315, Percentage = 33.79%\n",
      "Epoch 1/50, Training Loss: 1.0999, Training Accuracy: 0.3492, Validation Loss: 1.1528\n",
      "Epoch 2/50, Training Loss: 1.0972, Training Accuracy: 0.3572, Validation Loss: 1.1060\n",
      "Epoch 3/50, Training Loss: 1.0959, Training Accuracy: 0.3645, Validation Loss: 1.1368\n",
      "Epoch 4/50, Training Loss: 1.0954, Training Accuracy: 0.3620, Validation Loss: 1.1020\n",
      "Epoch 5/50, Training Loss: 1.0947, Training Accuracy: 0.3667, Validation Loss: 1.1062\n",
      "Epoch 6/50, Training Loss: 1.0937, Training Accuracy: 0.3667, Validation Loss: 1.1566\n",
      "Epoch 7/50, Training Loss: 1.0937, Training Accuracy: 0.3657, Validation Loss: 1.1117\n",
      "Epoch 8/50, Training Loss: 1.0928, Training Accuracy: 0.3700, Validation Loss: 1.1087\n",
      "Epoch 9/50, Training Loss: 1.0924, Training Accuracy: 0.3708, Validation Loss: 1.1182\n",
      "Early stopping triggered\n",
      "Accuracy: 0.3432\n",
      "Precision: 0.3412\n",
      "Recall: 0.3378\n",
      "F1-Score: 0.3217\n",
      "Confusion Matrix:\n",
      " [[1211  284  871]\n",
      " [1084  318  768]\n",
      " [1156  337  822]]\n"
     ]
    }
   ],
   "source": [
    "### Data preparation\n",
    "\n",
    "# Reduce the Dataset for the datapoints concerning rq2\n",
    "\n",
    "rq2_train_feat_dataset= train_feat_dataset.copy()\n",
    "processed_train_indexes, train_targets= ped.get_indexes_and_targets_by_rq(2, rq2_train_feat_dataset.features)\n",
    "rq2_train_feat_dataset.features= rq2_train_feat_dataset.features.iloc[processed_train_indexes]\n",
    "rq2_train_feat_dataset.features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "rq2_test_feat_dataset= test_feat_dataset.copy()\n",
    "processed_test_indexes, test_targets= ped.get_indexes_and_targets_by_rq(2, rq2_test_feat_dataset.features)\n",
    "rq2_test_feat_dataset.features= rq2_test_feat_dataset.features.iloc[processed_test_indexes]\n",
    "rq2_test_feat_dataset.features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Reduce the features that are correlated in the training data\n",
    "train_cols= rq2_train_feat_dataset.reduce_features(targets= train_targets, corr_threshold=0.75)\n",
    "rq2_test_feat_dataset.keep_only_specified_variable_columns(train_cols)\n",
    "\n",
    "# Normalize features\n",
    "normalization_params= rq2_train_feat_dataset.normalize_features()\n",
    "rq2_test_feat_dataset.apply_normalization(normalization_params)\n",
    "\n",
    "rq2_train_feat_dataset.objective_features.head()\n",
    "\n",
    "rq2_test_feat_dataset.objective_features.head()\n",
    "\n",
    "train_loader= rq2_train_feat_dataset.get_variable_features_loader(train_targets)\n",
    "test_loader= rq2_test_feat_dataset.get_variable_features_loader(test_targets)\n",
    "\n",
    "# Train dataset\n",
    "print_counts_and_percentages(train_targets)\n",
    "\n",
    "# Test dataset\n",
    "print_counts_and_percentages(test_targets)\n",
    "\n",
    "### Training\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "input_size= len(rq2_train_feat_dataset.variable_columns)\n",
    "output_size= 3\n",
    "num_epochs = 50\n",
    "\n",
    "parameters = {\n",
    "    'learning_rate': 0.0003,\n",
    "    'dense_units': 128,\n",
    "    'dense_layers': 2,\n",
    "    'dropout_rate': 0.2\n",
    "}\n",
    "\n",
    "model = FullyConnectedClassifier(input_size= input_size, output_size= output_size, parameters= parameters)\n",
    "\n",
    "model.train_model(train_loader, test_loader, num_epochs)\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "test_predictions = model.predict(test_loader)\n",
    "\n",
    "actual_labels = []\n",
    "for _, labels in test_loader:\n",
    "    actual_labels.extend(labels.tolist())\n",
    "\n",
    "correct_predictions = sum(p == t for p, t in zip(test_predictions, actual_labels))\n",
    "accuracy = correct_predictions / len(actual_labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Assuming your task is a classification task\n",
    "precision = precision_score(actual_labels, test_predictions, average='macro')\n",
    "recall = recall_score(actual_labels, test_predictions, average='macro')\n",
    "f1 = f1_score(actual_labels, test_predictions, average='macro')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(actual_labels, test_predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9446fe-ddeb-4ae5-bf39-a8c4a7d5cd12",
   "metadata": {},
   "source": [
    "## RQ3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4b82a9e-242a-4094-b87d-78f17c04c53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced variable features from 38 to 14.\n",
      "Variable features were properly normalized using 'zscore' method.\n",
      "Applied z-score normalization.\n",
      "Counts and Percentages:\n",
      "Class 0: Count = 19022, Percentage = 63.08%\n",
      "Class 1: Count = 4076, Percentage = 13.52%\n",
      "Class 2: Count = 3822, Percentage = 12.67%\n",
      "Class 3: Count = 3235, Percentage = 10.73%\n",
      "Counts and Percentages:\n",
      "Class 0: Count = 4110, Percentage = 54.02%\n",
      "Class 1: Count = 1602, Percentage = 21.06%\n",
      "Class 2: Count = 1371, Percentage = 18.02%\n",
      "Class 3: Count = 525, Percentage = 6.90%\n",
      "Epoch 1/50, Training Loss: 1.1116, Training Accuracy: 0.6107, Validation Loss: 2.1743\n",
      "Epoch 2/50, Training Loss: 1.0468, Training Accuracy: 0.6307, Validation Loss: 1.8690\n",
      "Epoch 3/50, Training Loss: 1.0361, Training Accuracy: 0.6311, Validation Loss: 1.7982\n",
      "Epoch 4/50, Training Loss: 1.0295, Training Accuracy: 0.6321, Validation Loss: 1.7735\n",
      "Epoch 5/50, Training Loss: 1.0251, Training Accuracy: 0.6332, Validation Loss: 1.8492\n",
      "Epoch 6/50, Training Loss: 1.0211, Training Accuracy: 0.6351, Validation Loss: 1.5380\n",
      "Epoch 7/50, Training Loss: 1.0184, Training Accuracy: 0.6362, Validation Loss: 1.6656\n",
      "Epoch 8/50, Training Loss: 1.0159, Training Accuracy: 0.6378, Validation Loss: 1.7347\n",
      "Epoch 9/50, Training Loss: 1.0140, Training Accuracy: 0.6378, Validation Loss: 1.6223\n",
      "Epoch 10/50, Training Loss: 1.0120, Training Accuracy: 0.6385, Validation Loss: 1.7196\n",
      "Epoch 11/50, Training Loss: 1.0102, Training Accuracy: 0.6396, Validation Loss: 1.6886\n",
      "Early stopping triggered\n",
      "Accuracy: 0.5382\n",
      "Precision: 0.2170\n",
      "Recall: 0.2503\n",
      "F1-Score: 0.1781\n",
      "Confusion Matrix:\n",
      " [[4089   13    0    8]\n",
      " [1593    4    0    5]\n",
      " [1368    1    0    2]\n",
      " [ 522    1    0    2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alvar\\anaconda3\\envs\\Plant-Reactivity-Analysis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "### Data preparation\n",
    "\n",
    "# Reduce the Dataset for the datapoints concerning rq3\n",
    "\n",
    "rq3_train_feat_dataset= train_feat_dataset.copy()\n",
    "processed_train_indexes, train_targets= ped.get_indexes_and_targets_by_rq(3, rq3_train_feat_dataset.features)\n",
    "rq3_train_feat_dataset.features= rq3_train_feat_dataset.features.iloc[processed_train_indexes]\n",
    "rq3_train_feat_dataset.features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "rq3_test_feat_dataset= test_feat_dataset.copy()\n",
    "processed_test_indexes, test_targets= ped.get_indexes_and_targets_by_rq(3, rq3_test_feat_dataset.features)\n",
    "rq3_test_feat_dataset.features= rq3_test_feat_dataset.features.iloc[processed_test_indexes]\n",
    "rq3_test_feat_dataset.features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Reduce the features that are correlated in the training data\n",
    "train_cols= rq3_train_feat_dataset.reduce_features(targets= train_targets, corr_threshold=0.75)\n",
    "rq3_test_feat_dataset.keep_only_specified_variable_columns(train_cols)\n",
    "\n",
    "# Normalize features\n",
    "normalization_params= rq3_train_feat_dataset.normalize_features()\n",
    "rq3_test_feat_dataset.apply_normalization(normalization_params)\n",
    "\n",
    "rq3_train_feat_dataset.objective_features.head()\n",
    "\n",
    "rq3_test_feat_dataset.objective_features.head()\n",
    "\n",
    "train_loader= rq3_train_feat_dataset.get_variable_features_loader(train_targets)\n",
    "test_loader= rq3_test_feat_dataset.get_variable_features_loader(test_targets)\n",
    "\n",
    "# Train dataset\n",
    "print_counts_and_percentages(train_targets)\n",
    "\n",
    "# Test dataset\n",
    "print_counts_and_percentages(test_targets)\n",
    "\n",
    "### Training\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "input_size= len(rq3_train_feat_dataset.variable_columns)\n",
    "output_size= 4\n",
    "num_epochs = 50\n",
    "\n",
    "parameters = {\n",
    "    'learning_rate': 0.0003,\n",
    "    'dense_units': 64,\n",
    "    'dense_layers': 1,\n",
    "    'dropout_rate': 0\n",
    "}\n",
    "\n",
    "model = FullyConnectedClassifier(input_size= input_size, output_size= output_size, parameters= parameters)\n",
    "\n",
    "model.train_model(train_loader, test_loader, num_epochs)\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "test_predictions = model.predict(test_loader)\n",
    "\n",
    "actual_labels = []\n",
    "for _, labels in test_loader:\n",
    "    actual_labels.extend(labels.tolist())\n",
    "\n",
    "correct_predictions = sum(p == t for p, t in zip(test_predictions, actual_labels))\n",
    "accuracy = correct_predictions / len(actual_labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Assuming your task is a classification task\n",
    "precision = precision_score(actual_labels, test_predictions, average='macro')\n",
    "recall = recall_score(actual_labels, test_predictions, average='macro')\n",
    "f1 = f1_score(actual_labels, test_predictions, average='macro')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(actual_labels, test_predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2518c098-1edb-4e4e-8998-18553d44bd8a",
   "metadata": {},
   "source": [
    "## RQ4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d02cffc-7d99-4976-8fa0-d9add1866aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced variable features from 38 to 17.\n",
      "Variable features were properly normalized using 'zscore' method.\n",
      "Applied z-score normalization.\n",
      "Counts and Percentages:\n",
      "Class 0: Count = 8082, Percentage = 26.80%\n",
      "Class 1: Count = 7558, Percentage = 25.06%\n",
      "Class 2: Count = 7516, Percentage = 24.92%\n",
      "Class 3: Count = 6999, Percentage = 23.21%\n",
      "Counts and Percentages:\n",
      "Class 0: Count = 2010, Percentage = 26.42%\n",
      "Class 1: Count = 1830, Percentage = 24.05%\n",
      "Class 2: Count = 1922, Percentage = 25.26%\n",
      "Class 3: Count = 1846, Percentage = 24.26%\n",
      "Epoch 1/50, Training Loss: 1.3809, Training Accuracy: 0.2801, Validation Loss: 1.4324\n",
      "Epoch 2/50, Training Loss: 1.3743, Training Accuracy: 0.2932, Validation Loss: 1.3976\n",
      "Epoch 3/50, Training Loss: 1.3715, Training Accuracy: 0.2999, Validation Loss: 1.4166\n",
      "Epoch 4/50, Training Loss: 1.3706, Training Accuracy: 0.2990, Validation Loss: 1.4107\n",
      "Epoch 5/50, Training Loss: 1.3702, Training Accuracy: 0.2987, Validation Loss: 1.3926\n",
      "Epoch 6/50, Training Loss: 1.3690, Training Accuracy: 0.3049, Validation Loss: 1.4095\n",
      "Epoch 7/50, Training Loss: 1.3681, Training Accuracy: 0.3040, Validation Loss: 1.3931\n",
      "Epoch 8/50, Training Loss: 1.3676, Training Accuracy: 0.3071, Validation Loss: 1.4485\n",
      "Epoch 9/50, Training Loss: 1.3668, Training Accuracy: 0.3052, Validation Loss: 1.4213\n",
      "Epoch 10/50, Training Loss: 1.3656, Training Accuracy: 0.3072, Validation Loss: 1.4188\n",
      "Early stopping triggered\n",
      "Accuracy: 0.2433\n",
      "Precision: 0.2451\n",
      "Recall: 0.2445\n",
      "F1-Score: 0.2388\n",
      "Confusion Matrix:\n",
      " [[483 615 273 639]\n",
      " [435 505 270 620]\n",
      " [501 549 271 601]\n",
      " [479 522 253 592]]\n"
     ]
    }
   ],
   "source": [
    "### Data preparation\n",
    "\n",
    "# Reduce the Dataset for the datapoints concerning rq4\n",
    "\n",
    "rq4_train_feat_dataset= train_feat_dataset.copy()\n",
    "processed_train_indexes, train_targets= ped.get_indexes_and_targets_by_rq(4, rq4_train_feat_dataset.features)\n",
    "rq4_train_feat_dataset.features= rq4_train_feat_dataset.features.iloc[processed_train_indexes]\n",
    "rq4_train_feat_dataset.features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "rq4_test_feat_dataset= test_feat_dataset.copy()\n",
    "processed_test_indexes, test_targets= ped.get_indexes_and_targets_by_rq(4, rq4_test_feat_dataset.features)\n",
    "rq4_test_feat_dataset.features= rq4_test_feat_dataset.features.iloc[processed_test_indexes]\n",
    "rq4_test_feat_dataset.features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Reduce the features that are correlated in the training data\n",
    "train_cols= rq4_train_feat_dataset.reduce_features(targets= train_targets, corr_threshold=0.75)\n",
    "rq4_test_feat_dataset.keep_only_specified_variable_columns(train_cols)\n",
    "\n",
    "# Normalize features\n",
    "normalization_params= rq4_train_feat_dataset.normalize_features()\n",
    "rq4_test_feat_dataset.apply_normalization(normalization_params)\n",
    "\n",
    "rq4_train_feat_dataset.objective_features.head()\n",
    "\n",
    "rq4_test_feat_dataset.objective_features.head()\n",
    "\n",
    "train_loader= rq4_train_feat_dataset.get_variable_features_loader(train_targets)\n",
    "test_loader= rq4_test_feat_dataset.get_variable_features_loader(test_targets)\n",
    "\n",
    "# Train dataset\n",
    "print_counts_and_percentages(train_targets)\n",
    "\n",
    "# Test dataset\n",
    "print_counts_and_percentages(test_targets)\n",
    "\n",
    "### Training\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "input_size= len(rq4_train_feat_dataset.variable_columns)\n",
    "output_size= 4\n",
    "num_epochs = 50\n",
    "\n",
    "parameters = {\n",
    "    'learning_rate': 0.0003,\n",
    "    'dense_units': 64,\n",
    "    'dense_layers': 2,\n",
    "    'dropout_rate': 0.2\n",
    "}\n",
    "\n",
    "model = FullyConnectedClassifier(input_size= input_size, output_size= output_size, parameters= parameters)\n",
    "\n",
    "model.train_model(train_loader, test_loader, num_epochs)\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "test_predictions = model.predict(test_loader)\n",
    "\n",
    "actual_labels = []\n",
    "for _, labels in test_loader:\n",
    "    actual_labels.extend(labels.tolist())\n",
    "\n",
    "correct_predictions = sum(p == t for p, t in zip(test_predictions, actual_labels))\n",
    "accuracy = correct_predictions / len(actual_labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Assuming your task is a classification task\n",
    "precision = precision_score(actual_labels, test_predictions, average='macro')\n",
    "recall = recall_score(actual_labels, test_predictions, average='macro')\n",
    "f1 = f1_score(actual_labels, test_predictions, average='macro')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(actual_labels, test_predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
