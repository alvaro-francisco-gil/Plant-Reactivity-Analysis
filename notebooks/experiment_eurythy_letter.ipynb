{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "501268a1-2347-46dd-ae4e-d4424b0261a9",
   "metadata": {},
   "source": [
    "# Experiment Eurythmy Letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcf03c35-b2aa-43be-b877-697d2f41c182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PlantReactivityAnalysis.features.features_dataset import FeaturesDataset\n",
    "from PlantReactivityAnalysis.models.experiment import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e27e9cd-2454-4464-b7ec-7ebf191103ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e753e-a150-4713-89fe-ee55f0a47f4e",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201f79aa-6c54-45b9-8590-1d4e4076c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_letters_signal_dataset_path= r\"..\\data\\processed\\feat_norm_letters_1_1_dataset_mean.pkl\"\n",
    "feat_dataset = FeaturesDataset.load(file_path= norm_letters_signal_dataset_path)\n",
    "feat_dataset.features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53f9dd1-6bd5-4b1f-ae2a-ab0aeb3ceac0",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd497b5a-6843-45c2-9d22-b847f9cc7dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dataset.prepare_dataset(drop_constant= False, drop_flatness_columns= True, drop_nan_columns= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfaf604-8bb4-43e2-afc8-2cac6d5675aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dataset.features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f3bd65-4f12-4f95-b675-74f23d101aa4",
   "metadata": {},
   "source": [
    "## RQ1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d9dc60-42bf-49e3-b9be-65982f5de922",
   "metadata": {},
   "source": [
    "Is there any difference in the signals when someone is performing eurythmy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa452b95-7c4e-4e57-bc09-477f319a28e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rq2= feat_dataset.return_subset_given_research_question(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92795233-5312-40c2-bcc4-f12027da517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_dataset, _, test_feat_dataset= rq2.split_dataset(split_by_wav= False,test_size= 0.2, val_size= 0, random_state= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7262c4-f677-4d44-8d17-ce350dd882ff",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d747c2b-158c-46d3-a7ab-1554a5c30d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the features that are correlated in the training data\n",
    "train_cols, feat_stats= train_feat_dataset.reduce_features_based_on_target(corr_threshold=0.8)\n",
    "test_feat_dataset.keep_only_specified_variable_columns(train_cols)\n",
    "\n",
    "# Normalize features ?????\n",
    "#normalization_params= train_feat_dataset.normalize_features()\n",
    "#test_feat_dataset.apply_normalization(normalization_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b84a33-8839-4502-b19f-5e642ec899ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_stats.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c970865-b9c7-4ef9-9944-e6014c62817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_dataset.features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55003dfa-44b3-4c3c-9264-e0fe524dd042",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat_dataset.features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47035379-d2dd-41d0-a018-23f14fd98eaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_feat_dataset.print_target_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335e9a87-7d5b-448a-947a-55cbb2db2060",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat_dataset.print_target_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b943562c-a648-4bb2-9f94-e9b6e7e469d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= train_feat_dataset.objective_features\n",
    "test_df= test_feat_dataset.objective_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea09659-65ee-4859-9aa6-bf238e0988da",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(train_df, test_df, 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb4c1df-5fa6-4920-9c26-031f14f4f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_par_dict = {\n",
    "            \"svm\": np.array([0.001, 0.01, 0.5, 1.0, 5.0, 10.0, 20.0]),\n",
    "            \"svm_rbf\": np.array([0.001, 0.01, 0.5, 1.0, 5.0, 10.0, 20.0]),\n",
    "            \"randomforest\": np.array([10, 25, 50, 100, 200, 500]),\n",
    "            \"gradientboosting\": np.array([10, 25, 50, 100, 200, 500]),\n",
    "            \"extratrees\": np.array([10, 25, 50, 100, 200, 500]),\n",
    "            \"gaussiannb\": []  # Naive Bayes does not require parameter tuning for this example\n",
    "        }\n",
    "\n",
    "experiment.run_all_models(classifier_par_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef696155-0eef-40a8-b0e1-27a50a09b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.print_best_result(metric='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423922b4-2b77-493e-bee9-333fc2ec32b9",
   "metadata": {},
   "source": [
    "## RQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0986c19-6265-48e0-a18a-43cd53a50fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rq1= feat_dataset.return_subset_given_research_question(1)\n",
    "train_feat_dataset, _, test_feat_dataset= rq1.split_dataset(split_by_wav= False,test_size= 0.2, val_size= 0, random_state= True)\n",
    "\n",
    "# Reduce the features that are correlated in the training data\n",
    "train_cols, feat_stats= train_feat_dataset.reduce_features_based_on_target(corr_threshold=0.8)\n",
    "test_feat_dataset.keep_only_specified_variable_columns(train_cols)\n",
    "\n",
    "# Normalize features ?????\n",
    "normalization_params= train_feat_dataset.normalize_features()\n",
    "test_feat_dataset.apply_normalization(normalization_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9bbe46-5883-40a5-bd92-4757f9a32d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_stats.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7abde2-bff4-4f25-87d3-2dd2ef554532",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_dataset.features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068a07fe-2f7b-4147-9194-a4f27170541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat_dataset.features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1dbefb-9faf-4281-8078-03cbc8a56979",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_dataset.print_target_distribution()\n",
    "test_feat_dataset.print_target_distribution()\n",
    "\n",
    "train_df= train_feat_dataset.objective_features\n",
    "test_df= test_feat_dataset.objective_features\n",
    "\n",
    "experiment = Experiment(train_df, test_df, 'target')\n",
    "experiment.run_all_models(classifier_par_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e9ba2c-0c7f-4ca7-a8f9-33b88ac9b28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.print_best_result(metric='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9446fe-ddeb-4ae5-bf39-a8c4a7d5cd12",
   "metadata": {},
   "source": [
    "## RQ3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b82a9e-242a-4094-b87d-78f17c04c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data preparation\n",
    "\n",
    "# Reduce the Dataset for the datapoints concerning rq3\n",
    "\n",
    "rq3_train_feat_dataset= train_feat_dataset.copy()\n",
    "processed_train_indexes, train_targets= ped.get_indexes_and_targets_by_rq(3, rq3_train_feat_dataset.features)\n",
    "rq3_train_feat_dataset.features= rq3_train_feat_dataset.features.iloc[processed_train_indexes]\n",
    "rq3_train_feat_dataset.features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "rq3_test_feat_dataset= test_feat_dataset.copy()\n",
    "processed_test_indexes, test_targets= ped.get_indexes_and_targets_by_rq(3, rq3_test_feat_dataset.features)\n",
    "rq3_test_feat_dataset.features= rq3_test_feat_dataset.features.iloc[processed_test_indexes]\n",
    "rq3_test_feat_dataset.features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Reduce the features that are correlated in the training data\n",
    "train_cols= rq3_train_feat_dataset.reduce_features(targets= train_targets, corr_threshold=0.75)\n",
    "rq3_test_feat_dataset.keep_only_specified_variable_columns(train_cols)\n",
    "\n",
    "# Normalize features\n",
    "normalization_params= rq3_train_feat_dataset.normalize_features()\n",
    "rq3_test_feat_dataset.apply_normalization(normalization_params)\n",
    "\n",
    "rq3_train_feat_dataset.objective_features.head()\n",
    "\n",
    "rq3_test_feat_dataset.objective_features.head()\n",
    "\n",
    "train_loader= rq3_train_feat_dataset.get_variable_features_loader(train_targets)\n",
    "test_loader= rq3_test_feat_dataset.get_variable_features_loader(test_targets)\n",
    "\n",
    "# Train dataset\n",
    "print_counts_and_percentages(train_targets)\n",
    "\n",
    "# Test dataset\n",
    "print_counts_and_percentages(test_targets)\n",
    "\n",
    "### Training\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "input_size= len(rq3_train_feat_dataset.variable_columns)\n",
    "output_size= 4\n",
    "num_epochs = 50\n",
    "\n",
    "parameters = {\n",
    "    'learning_rate': 0.0003,\n",
    "    'dense_units': 64,\n",
    "    'dense_layers': 1,\n",
    "    'dropout_rate': 0\n",
    "}\n",
    "\n",
    "model = FullyConnectedClassifier(input_size= input_size, output_size= output_size, parameters= parameters)\n",
    "\n",
    "model.train_model(train_loader, test_loader, num_epochs)\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "test_predictions = model.predict(test_loader)\n",
    "\n",
    "actual_labels = []\n",
    "for _, labels in test_loader:\n",
    "    actual_labels.extend(labels.tolist())\n",
    "\n",
    "correct_predictions = sum(p == t for p, t in zip(test_predictions, actual_labels))\n",
    "accuracy = correct_predictions / len(actual_labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Assuming your task is a classification task\n",
    "precision = precision_score(actual_labels, test_predictions, average='macro')\n",
    "recall = recall_score(actual_labels, test_predictions, average='macro')\n",
    "f1 = f1_score(actual_labels, test_predictions, average='macro')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(actual_labels, test_predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2518c098-1edb-4e4e-8998-18553d44bd8a",
   "metadata": {},
   "source": [
    "## RQ4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d02cffc-7d99-4976-8fa0-d9add1866aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data preparation\n",
    "\n",
    "# Reduce the Dataset for the datapoints concerning rq4\n",
    "\n",
    "rq4_train_feat_dataset= train_feat_dataset.copy()\n",
    "processed_train_indexes, train_targets= ped.get_indexes_and_targets_by_rq(4, rq4_train_feat_dataset.features)\n",
    "rq4_train_feat_dataset.features= rq4_train_feat_dataset.features.iloc[processed_train_indexes]\n",
    "rq4_train_feat_dataset.features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "rq4_test_feat_dataset= test_feat_dataset.copy()\n",
    "processed_test_indexes, test_targets= ped.get_indexes_and_targets_by_rq(4, rq4_test_feat_dataset.features)\n",
    "rq4_test_feat_dataset.features= rq4_test_feat_dataset.features.iloc[processed_test_indexes]\n",
    "rq4_test_feat_dataset.features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Reduce the features that are correlated in the training data\n",
    "train_cols= rq4_train_feat_dataset.reduce_features(targets= train_targets, corr_threshold=0.75)\n",
    "rq4_test_feat_dataset.keep_only_specified_variable_columns(train_cols)\n",
    "\n",
    "# Normalize features\n",
    "normalization_params= rq4_train_feat_dataset.normalize_features()\n",
    "rq4_test_feat_dataset.apply_normalization(normalization_params)\n",
    "\n",
    "rq4_train_feat_dataset.objective_features.head()\n",
    "\n",
    "rq4_test_feat_dataset.objective_features.head()\n",
    "\n",
    "train_loader= rq4_train_feat_dataset.get_variable_features_loader(train_targets)\n",
    "test_loader= rq4_test_feat_dataset.get_variable_features_loader(test_targets)\n",
    "\n",
    "# Train dataset\n",
    "print_counts_and_percentages(train_targets)\n",
    "\n",
    "# Test dataset\n",
    "print_counts_and_percentages(test_targets)\n",
    "\n",
    "### Training\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "input_size= len(rq4_train_feat_dataset.variable_columns)\n",
    "output_size= 4\n",
    "num_epochs = 50\n",
    "\n",
    "parameters = {\n",
    "    'learning_rate': 0.0003,\n",
    "    'dense_units': 64,\n",
    "    'dense_layers': 2,\n",
    "    'dropout_rate': 0.2\n",
    "}\n",
    "\n",
    "model = FullyConnectedClassifier(input_size= input_size, output_size= output_size, parameters= parameters)\n",
    "\n",
    "model.train_model(train_loader, test_loader, num_epochs)\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "test_predictions = model.predict(test_loader)\n",
    "\n",
    "actual_labels = []\n",
    "for _, labels in test_loader:\n",
    "    actual_labels.extend(labels.tolist())\n",
    "\n",
    "correct_predictions = sum(p == t for p, t in zip(test_predictions, actual_labels))\n",
    "accuracy = correct_predictions / len(actual_labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Assuming your task is a classification task\n",
    "precision = precision_score(actual_labels, test_predictions, average='macro')\n",
    "recall = recall_score(actual_labels, test_predictions, average='macro')\n",
    "f1 = f1_score(actual_labels, test_predictions, average='macro')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(actual_labels, test_predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Plant-Reactivity-Analysis)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
